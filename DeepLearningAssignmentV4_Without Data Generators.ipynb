{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset and embeds test data.\n",
    "The test data is embedded using the weights of the final dense layer, just\n",
    "before the classification head. This embedding can then be visualized using\n",
    "TensorBoard's Embedding Projector.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from os import makedirs\n",
    "from os.path import exists, join\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "log_dir = './logs-cnn'\n",
    "\n",
    "if not exists(log_dir):\n",
    "    makedirs(log_dir)\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save class labels to disk to color data points in TensorBoard accordingly\n",
    "with open(join(log_dir, 'metadata.tsv'), 'w') as f:\n",
    "    np.savetxt(f, y_test)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(batch_size=batch_size,\n",
    "                          embeddings_freq=1,\n",
    "                          embeddings_layer_names=['features'],\n",
    "                          embeddings_metadata='metadata.tsv',\n",
    "                          embeddings_data=x_test,\n",
    "                          histogram_freq=0, \n",
    "                          write_graph=True, \n",
    "                          write_grads=False, \n",
    "                          write_images=False, \n",
    "                          update_freq='epoch',\n",
    "                          log_dir=log_dir )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', name='features'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0703 11:13:00.422507  4116 deprecation_wrapper.py:119] From C:\\Users\\Noor\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0703 11:13:00.710800  4116 deprecation_wrapper.py:119] From C:\\Users\\Noor\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0703 11:13:00.828517  4116 deprecation_wrapper.py:119] From C:\\Users\\Noor\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0703 11:13:01.098136  4116 deprecation_wrapper.py:119] From C:\\Users\\Noor\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0703 11:13:01.109963  4116 deprecation_wrapper.py:119] From C:\\Users\\Noor\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0703 11:13:01.256575  4116 deprecation.py:506] From C:\\Users\\Noor\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0703 11:13:01.462018  4116 deprecation_wrapper.py:119] From C:\\Users\\Noor\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0703 11:13:01.471287  4116 deprecation_wrapper.py:119] From C:\\Users\\Noor\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0703 11:13:01.975546  4116 deprecation.py:323] From C:\\Users\\Noor\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0703 11:13:03.699476  4116 deprecation_wrapper.py:119] From C:\\Users\\Noor\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0703 11:13:03.699476  4116 deprecation_wrapper.py:119] From C:\\Users\\Noor\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "W0703 11:13:04.016844  4116 deprecation_wrapper.py:119] From C:\\Users\\Noor\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:887: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 176s 3ms/step - loss: 0.2780 - acc: 0.9139 - val_loss: 0.0593 - val_acc: 0.9802\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 175s 3ms/step - loss: 0.0913 - acc: 0.9731 - val_loss: 0.0394 - val_acc: 0.9860\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 173s 3ms/step - loss: 0.0680 - acc: 0.9804 - val_loss: 0.0369 - val_acc: 0.9878\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 172s 3ms/step - loss: 0.0552 - acc: 0.9837 - val_loss: 0.0323 - val_acc: 0.9882\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 174s 3ms/step - loss: 0.0476 - acc: 0.9859 - val_loss: 0.0284 - val_acc: 0.9910\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 173s 3ms/step - loss: 0.0423 - acc: 0.9871 - val_loss: 0.0275 - val_acc: 0.9904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0703 11:33:42.772357  4116 deprecation.py:323] From C:\\Users\\Noor\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 174s 3ms/step - loss: 0.0374 - acc: 0.9885 - val_loss: 0.0269 - val_acc: 0.9904\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 198s 3ms/step - loss: 0.0361 - acc: 0.9889 - val_loss: 0.0273 - val_acc: 0.9911\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 196s 3ms/step - loss: 0.0312 - acc: 0.9910 - val_loss: 0.0328 - val_acc: 0.9892\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 201s 3ms/step - loss: 0.0302 - acc: 0.9907 - val_loss: 0.0262 - val_acc: 0.9909\n",
      "Test loss: 0.026161733050311522\n",
      "Test accuracy: 0.9909\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          callbacks=[tensorboard ],\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# You can now launch tensorboard with `tensorboard --logdir=./logs` on your\n",
    "# command line and then go to http://localhost:6006/#projector to view the\n",
    "# embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep NN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset and embeds test data.\n",
    "The test data is embedded using the weights of the final dense layer, just\n",
    "before the classification head. This embedding can then be visualized using\n",
    "TensorBoard's Embedding Projector.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from os import makedirs\n",
    "from os.path import exists, join\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "# To ignore keep_dims warning\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "log_dir = './logs-DNN'\n",
    "\n",
    "if not exists(log_dir):\n",
    "    makedirs(log_dir)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "#train_images2 = train_images.reshape(60000, 784)     \n",
    "#test_images2 = test_images.reshape(10000, 784)\n",
    "\n",
    "#train_images2 = train_images2.astype('float32')     \n",
    "#test_images2 = test_images2.astype('float32')     \n",
    "\n",
    "train_images2 = train_images / 255.0\n",
    "test_images2 = test_images / 255.0\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "train_labels2 = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels2 = keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save class labels to disk to color data points in TensorBoard accordingly\n",
    "with open(join(log_dir, 'metadata2.tsv'), 'w') as f:\n",
    "    np.savetxt(f, test_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard2 = TensorBoard(batch_size=batch_size,\n",
    "                          embeddings_freq=1,\n",
    "                          embeddings_layer_names=['features'],\n",
    "                          embeddings_metadata='metadata.tsv',\n",
    "                          embeddings_data=test_images2,\n",
    "                          histogram_freq=0, \n",
    "                          write_graph=True, \n",
    "                          write_grads=False, \n",
    "                          write_images=False, \n",
    "                          update_freq='epoch',\n",
    "                          log_dir=log_dir )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Flatten(input_shape=(28, 28))),\n",
    "model2.add(Dense(128, activation=tf.nn.relu, name='features'))\n",
    "# output = relu (dot (W, input) + bias)\n",
    "model2.add(Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3579 - acc: 0.9008 - val_loss: 0.2163 - val_acc: 0.9362\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1721 - acc: 0.9512 - val_loss: 0.1382 - val_acc: 0.9591\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1270 - acc: 0.9638 - val_loss: 0.1128 - val_acc: 0.9665\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.1015 - acc: 0.971 - 3s 49us/step - loss: 0.1012 - acc: 0.9714 - val_loss: 0.1018 - val_acc: 0.9702\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0844 - acc: 0.9762 - val_loss: 0.0930 - val_acc: 0.9716\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0723 - acc: 0.9797 - val_loss: 0.0865 - val_acc: 0.9736\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0626 - acc: 0.9817 - val_loss: 0.0783 - val_acc: 0.9760\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.0546 - acc: 0.9847 - val_loss: 0.0753 - val_acc: 0.9778\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0488 - acc: 0.9868 - val_loss: 0.0763 - val_acc: 0.9778\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0434 - acc: 0.9883 - val_loss: 0.0712 - val_acc: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xf8323b828>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_images2, train_labels2,\n",
    "          batch_size=batch_size,\n",
    "          callbacks=[tensorboard2],\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(test_images2, test_labels2)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.07124984702132642\n",
      "Test accuracy: 0.9782\n"
     ]
    }
   ],
   "source": [
    "score = model2.evaluate(test_images2, test_labels2, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# You can now launch tensorboard with `tensorboard --logdir=./logs` on your\n",
    "# command line and then go to http://localhost:6006/#projector to view the\n",
    "# embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "duration = 1000  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)\n",
    "winsound.Beep(frequency, duration)\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
